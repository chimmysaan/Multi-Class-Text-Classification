In this project I used the tools and concepts listed below:

PROGRAMMING LANGUAGE
- Python 3.12

DEEP LEARNING FRAMEWORKS
- TensorFlow
- Keras

MACHINE LEARNING LIBRARIES
- Scikit-learn (sklearn)
  - Random Forest Classifier
  - Logistic Regression
  - Multinomial Naive Bayes
  - Train-Test Split
  - Label Encoder

NATURAL LANGUAGE PROCESSING (NLP)
- NLTK (Natural Language Toolkit)
  - Tokenization
  - Stopword Removal
  - WordNet Lemmatizer
  - Corpus Processing

WORD EMBEDDINGS & REPRESENTATIONS
- Gensim
- Word2Vec (Skip-gram model)
- TF-IDF (Term Frequency-Inverse Document Frequency)

DATA PROCESSING & ANALYSIS
- NumPy
- Pandas

VISUALIZATION LIBRARIES
- Matplotlib
- Seaborn

NEURAL NETWORK ARCHITECTURES
- Deep Neural Network (DNN)
- Recurrent Neural Networks (RNN)
  - Simple RNN
  - Gated Recurrent Unit (GRU)
  - Long Short-Term Memory (LSTM)
  - Bidirectional RNN (BiRNN)
  - Bidirectional GRU (BiGRU)
  - Bidirectional LSTM (BiLSTM)

TEXT PREPROCESSING TECHNIQUES
- Tokenization
- Stopword Removal
- Lemmatization
- Text Normalization
- Padding & Truncation
- Vocabulary Building

MODEL EVALUATION METRICS
- Accuracy Score
- F1 Score (Macro-averaged)
- F1 Score (Weighted)
- Confusion Matrix
- Classification Report

DEVELOPMENT ENVIRONMENT
- Google Colab
- Jupyter Notebook
- GPU Computing (NVIDIA Tesla T4)
- CUDA 12.4

ADDITIONAL UTILITIES
- tqdm (Progress Bars)
- Reproducibility (Random Seed Setting)

KEY TECHNICAL SKILLS DEMONSTRATED
- Multi-class Text Classification
- Supervised Learning
- Deep Learning
- Sequential Modeling
- Hyperparameter Tuning
- Model Evaluation & Comparison
- Exploratory Data Analysis (EDA)
- Feature Engineering
- GPU-accelerated Computing

analysis: NumPy, Pandas, Matplotlib, Seaborn
- Tools: Google Colab, Jupyter Notebook, GPU Computing (CUDA)
- Techniques: Text Classification, Sequential Modeling, Hyperparameter Tuning, Model Evaluation
